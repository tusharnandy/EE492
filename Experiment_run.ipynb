{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "630bf96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/infonas/data/tnandy/fa_ant/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import math\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import os\n",
    "from math import floor\n",
    "from tqdm import tqdm\n",
    "from blackbox_preaudit import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92228ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_device = 0\n",
    "device = torch.device(f'cuda:{num_device}' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2cdebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vae import VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b46d3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae1 = VAE(102, 64, 16)\n",
    "checkpoint = torch.load('checkpoints/vae1.pth')\n",
    "vae1.load_state_dict(checkpoint['model_state_dict'])\n",
    "vae1.to(device)\n",
    "vae1.eval();\n",
    "\n",
    "vae0 = VAE(102, 64, 16)\n",
    "checkpoint = torch.load('checkpoints/vae0.pth')\n",
    "vae0.load_state_dict(checkpoint['model_state_dict'])\n",
    "vae0.to(device)\n",
    "vae0.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69928115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55459534",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3260687",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dim = 102\n",
    "\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "def train(train_x, train_y):\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    model = ExactGPModel(train_x, train_y, likelihood)\n",
    "    model.to(device)\n",
    "    likelihood.to(device)\n",
    "    training_iterations = 60\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "    iterator = range(training_iterations)\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "    for i in range(training_iterations):\n",
    "        # Zero backprop gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Get output from model\n",
    "        output = model(train_x.to(device))\n",
    "        # Calc loss and backprop derivatives\n",
    "        loss = -mll(output, train_y.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73764f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_and_discard(database, sample_size):\n",
    "    samples = database.sample(sample_size)\n",
    "    database.drop(index=samples.index, inplace=True)\n",
    "    database.reset_index(drop=True, inplace=True)\n",
    "    return samples, database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b67f5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ignite_pd(dataframe, split=False):\n",
    "    if split:\n",
    "        x,y = dataframe.drop(columns=dataframe.columns[-1]).values, dataframe[dataframe.columns[-1]].values\n",
    "        return torch.Tensor(x.astype(np.float32)).to(device), torch.Tensor(y.astype(np.float32)).to(device)\n",
    "    else:\n",
    "        return torch.tensor(dataframe.values.astype(np.float32)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51dd0db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=102, out_features=50, bias=True)\n",
       "  (act): ReLU()\n",
       "  (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blackbox = Net()\n",
    "blackbox.load_state_dict(torch.load('checkpoints/blackbox_preaudit.pth', map_location=device))\n",
    "blackbox.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c286a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = pd.read_csv(\"../Data/data1.csv\")\n",
    "df_base.drop(['Unnamed: 0'], axis=1, inplace = True)\n",
    "\n",
    "df_base_pos = df_base[df_base['gender_Female'] > 0]\n",
    "df_base_neg = df_base[df_base['gender_Female'] <= 0]\n",
    "\n",
    "df_base_neg = df_base_neg.reset_index(drop=True).copy().drop(columns='income')\n",
    "df_base_pos = df_base_pos.reset_index(drop=True).copy().drop(columns='income')\n",
    "\n",
    "sample_pos, df_base_pos = sample_and_discard(df_base_pos, 1000)\n",
    "pos_queried = ignite_pd(sample_pos)\n",
    "pos_labels = blackbox(pos_queried)\n",
    "\n",
    "# sample_neg, df_base_neg = sample_and_discard(df_base_neg, 1000)\n",
    "# neg_queried = ignite_pd(sample_neg)\n",
    "# neg_labels = blackbox(neg_queried)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36331ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_954517/520628438.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(neg_queried),\n",
      "/tmp/ipykernel_954517/520628438.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(neg_labels).flatten()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianLikelihood(\n",
       "  (noise_covar): HomoskedasticNoise(\n",
       "    (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_neg, likelihood_neg = train(\n",
    "    torch.tensor(neg_queried),\n",
    "    torch.tensor(neg_labels).flatten()\n",
    ")\n",
    "\n",
    "model_neg.eval()\n",
    "likelihood_neg.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e690f3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 4000/4000 [34:14<00:00,  1.95it/s]\n"
     ]
    }
   ],
   "source": [
    "candidates = []\n",
    "for epoch_outer in tqdm(range(1, 4001)):\n",
    "    x0_random = torch.normal(0.,1.,size=(1,101), requires_grad=True)\n",
    "    optimizer0 = torch.optim.AdamW((x0_random,), lr=10)\n",
    "    best_loss = 10e5\n",
    "    count = 0\n",
    "    losses = []\n",
    "    for epoch in range(1,100):\n",
    "        optimizer0.zero_grad()\n",
    "        x0_samples, _, _ = vae1(torch.concatenate([x0_random, torch.Tensor([[0.0]])], axis=1).to(device))\n",
    "        var0 = likelihood_neg(model_neg(x0_samples.to(device))).variance\n",
    "        loss = -var0\n",
    "        loss.backward()\n",
    "        optimizer0.step()\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            count = 0\n",
    "            losses.append(loss)\n",
    "        else:\n",
    "            count += 1\n",
    "        if count  == 5:\n",
    "            break\n",
    "    candidates.append(torch.concatenate([x0_random.detach().clone(), torch.Tensor([[0.0]])], axis=1))\n",
    "    \n",
    "    if epoch_outer % 500 == 0:\n",
    "        new_vals = torch.concatenate(candidates)\n",
    "        new_queries, _, _ = vae1(new_vals.to(device))\n",
    "        new_labels = blackbox(new_queries)\n",
    "        neg_queried = torch.concatenate([neg_queried, new_queries])\n",
    "        neg_labels = torch.concatenate([neg_labels, new_labels])\n",
    "        model_neg, likelihood_neg = train(\n",
    "            neg_queried.detach().clone(),\n",
    "            neg_labels.detach().clone().flatten())\n",
    "        model_neg.eval()\n",
    "        likelihood_neg.eval()\n",
    "        candidates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4304abc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 102])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_queried.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "716d9b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_954517/4059754406.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(pos_queried),\n",
      "/tmp/ipykernel_954517/4059754406.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(pos_labels).flatten())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianLikelihood(\n",
       "  (noise_covar): HomoskedasticNoise(\n",
       "    (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### training the GP ####\n",
    "model_pos, likelihood_pos = train(\n",
    "    torch.tensor(pos_queried),\n",
    "    torch.tensor(pos_labels).flatten())\n",
    "model_pos.eval()\n",
    "likelihood_pos.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adf48c50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▉                                                                      | 499/4000 [04:20<30:21,  1.92it/s]/tmp/ipykernel_954517/712994024.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(pos_queried),\n",
      "/tmp/ipykernel_954517/712994024.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(pos_labels).flatten())\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 4000/4000 [38:08<00:00,  1.75it/s]\n"
     ]
    }
   ],
   "source": [
    "candidates = []\n",
    "for epoch_outer in tqdm(range(1, 4001)):\n",
    "    x1_random = torch.normal(0.,1.,size=(1,101), requires_grad=True)\n",
    "    optimizer1 = torch.optim.AdamW((x1_random,), lr=10)\n",
    "    best_loss = 10e5\n",
    "    count = 0\n",
    "    losses = []\n",
    "    for epoch in range(1,100):\n",
    "        optimizer1.zero_grad()\n",
    "        x1_samples, _, _ = vae1(torch.concatenate([x1_random, torch.Tensor([[1.0]])], axis=1).to(device))\n",
    "        var1 = likelihood_pos(model_pos(x1_samples.to(device))).variance\n",
    "        loss = -var1\n",
    "        loss.backward()\n",
    "        optimizer1.step()\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            count = 0\n",
    "            losses.append(loss)\n",
    "        else:\n",
    "            count += 1\n",
    "        if count  == 5:\n",
    "            break\n",
    "    candidates.append(torch.concatenate([x1_random.detach().clone(), torch.Tensor([[1.0]])], axis=1))\n",
    "    \n",
    "    if epoch_outer % 500 == 0:\n",
    "        new_vals = torch.concatenate(candidates)\n",
    "        new_queries, _, _ = vae1(new_vals.to(device))\n",
    "        new_labels = blackbox(new_queries)\n",
    "        pos_queried = torch.concatenate([pos_queried, new_queries])\n",
    "        pos_labels = torch.concatenate([pos_labels, new_labels])\n",
    "        model_pos, likelihood_pos = train(\n",
    "            torch.tensor(pos_queried),\n",
    "            torch.tensor(pos_labels).flatten())\n",
    "        model_pos.eval()\n",
    "        likelihood_pos.eval()\n",
    "        candidates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5a410e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_parity = torch.abs(pos_labels.mean() - neg_labels.mean()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d0c3c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pos = ignite_pd(df_base[df_base['gender_Female'] == 1].drop(columns='income'))\n",
    "X_neg = ignite_pd(df_base[df_base['gender_Female'] == 0].drop(columns='income'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48e16821",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_parity = torch.abs(blackbox(X_pos).mean() - blackbox(X_neg).mean()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30e8983f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0012248754501342773 0.007420867681503296\n"
     ]
    }
   ],
   "source": [
    "print(estimated_parity, actual_parity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4502a63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error =  83.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"error = \", np.round(np.abs(estimated_parity-actual_parity)*100/actual_parity), \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "1623887a4657fbc55005e133332f3be3f5efee82a88b4990fa1707cdaeddf772"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
