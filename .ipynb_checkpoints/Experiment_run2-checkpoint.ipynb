{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13baee03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : Cuda libraries were not detected on the system ; using cpu only mode\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import utils\n",
    "import torch\n",
    "import pandas as pd\n",
    "import gpytorch\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from gpytorch.models import ExactGP\n",
    "from gpytorch.likelihoods import DirichletClassificationLikelihood\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import ScaleKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df10c5c0-9309-421c-8601-4e2aee0a4167",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 16 03:46:50 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.86       Driver Version: 470.86       CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA TITAN RTX    Off  | 00000000:3B:00.0 Off |                  N/A |\n",
      "| 41%   32C    P8    13W / 280W |      3MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A6000    Off  | 00000000:86:00.0 Off |                  Off |\n",
      "| 38%   59C    P8    17W / 300W |   1225MiB / 48685MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA RTX A6000    Off  | 00000000:AF:00.0 Off |                  Off |\n",
      "| 30%   60C    P2    88W / 300W |   1341MiB / 48685MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    1   N/A  N/A   1258742      C   ...aniket/my_env/bin/python3     1223MiB |\n",
      "|    2   N/A  N/A   1978050      C   python                            495MiB |\n",
      "|    2   N/A  N/A   1993103      C   python                            377MiB |\n",
      "|    2   N/A  N/A   1997195      C   python                            467MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e0e42c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5774c74-3b4a-46ce-9e04-0e66f33a5484",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "419930ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DirichletGPModel(ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, num_classes):\n",
    "        super(DirichletGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = ConstantMean(batch_shape=torch.Size((num_classes,)))\n",
    "        self.covar_module = ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel(batch_shape=torch.Size((num_classes,))),\n",
    "            batch_shape=torch.Size((num_classes,)),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "def train(train_x, train_y, device_idx=0):\n",
    "    device = torch.device(f'cuda:{device_idx}' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    likelihood = DirichletClassificationLikelihood(train_y, learn_additional_noise=True).cuda()\n",
    "    model = DirichletGPModel(train_x, likelihood.transformed_targets, likelihood, num_classes=likelihood.num_classes).cuda()\n",
    "    \n",
    "    model.to(device)\n",
    "    likelihood.to(device)\n",
    "    \n",
    "    training_iterations = 50\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "    \n",
    "    for i in tqdm(range(training_iterations)):\n",
    "        # Zero backprop gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Get output from model\n",
    "        output = model(train_x)\n",
    "        # Calc loss and backprop derivatives\n",
    "        loss = -mll(output, train_y).sum()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return model, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b387492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfx, dfy, _ = utils.get_dataset('adult_income', return_dataframe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9581b9b3-da68-4817-944c-02228ab08e6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "cols = dfx.columns[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4bd1631-a579-41d2-b838-ed61e280576c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'capital_gain', 'capital_loss', 'hours_per_week'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31b283ba-df1b-488d-8ae9-cb7e19916f7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfx_1 = dfx.loc[dfx.gender == 1]\n",
    "dfx_0 = dfx.loc[dfx.gender == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8060f19-3ed5-40ca-8c91-c358d48ec577",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_State-gov</th>\n",
       "      <th>workclass_Self-emp-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>native_country_Jamaica</th>\n",
       "      <th>native_country_Ecuador</th>\n",
       "      <th>native_country_Yugoslavia</th>\n",
       "      <th>native_country_Hungary</th>\n",
       "      <th>native_country_Hong</th>\n",
       "      <th>native_country_Greece</th>\n",
       "      <th>native_country_Trinadad&amp;Tobago</th>\n",
       "      <th>native_country_Outlying-US(Guam-USVI-etc)</th>\n",
       "      <th>native_country_France</th>\n",
       "      <th>native_country_Holand-Netherlands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48827</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48830</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>52</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14919 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  capital_gain  capital_loss  hours_per_week  workclass_Private  \\\n",
       "8       24             0             0              40                  1   \n",
       "12      26             0             0              39                  1   \n",
       "17      43             0             0              30                  1   \n",
       "18      37             0             0              20                  1   \n",
       "21      34             0             0              35                  1   \n",
       "...    ...           ...           ...             ...                ...   \n",
       "48827   37             0             0              40                  1   \n",
       "48830   43             0             0              40                  0   \n",
       "48837   27             0             0              38                  1   \n",
       "48839   58             0             0              40                  1   \n",
       "48841   52         15024             0              40                  0   \n",
       "\n",
       "       workclass_Local-gov  workclass_Self-emp-not-inc  workclass_Federal-gov  \\\n",
       "8                        0                           0                      0   \n",
       "12                       0                           0                      0   \n",
       "17                       0                           0                      0   \n",
       "18                       0                           0                      0   \n",
       "21                       0                           0                      0   \n",
       "...                    ...                         ...                    ...   \n",
       "48827                    0                           0                      0   \n",
       "48830                    0                           0                      0   \n",
       "48837                    0                           0                      0   \n",
       "48839                    0                           0                      0   \n",
       "48841                    0                           0                      0   \n",
       "\n",
       "       workclass_State-gov  workclass_Self-emp-inc  ...  \\\n",
       "8                        0                       0  ...   \n",
       "12                       0                       0  ...   \n",
       "17                       0                       0  ...   \n",
       "18                       0                       0  ...   \n",
       "21                       0                       0  ...   \n",
       "...                    ...                     ...  ...   \n",
       "48827                    0                       0  ...   \n",
       "48830                    1                       0  ...   \n",
       "48837                    0                       0  ...   \n",
       "48839                    0                       0  ...   \n",
       "48841                    0                       1  ...   \n",
       "\n",
       "       native_country_Jamaica  native_country_Ecuador  \\\n",
       "8                           0                       0   \n",
       "12                          0                       0   \n",
       "17                          0                       0   \n",
       "18                          0                       0   \n",
       "21                          0                       0   \n",
       "...                       ...                     ...   \n",
       "48827                       0                       0   \n",
       "48830                       0                       0   \n",
       "48837                       0                       0   \n",
       "48839                       0                       0   \n",
       "48841                       0                       0   \n",
       "\n",
       "       native_country_Yugoslavia  native_country_Hungary  native_country_Hong  \\\n",
       "8                              0                       0                    0   \n",
       "12                             0                       0                    0   \n",
       "17                             0                       0                    0   \n",
       "18                             0                       0                    0   \n",
       "21                             0                       0                    0   \n",
       "...                          ...                     ...                  ...   \n",
       "48827                          0                       0                    0   \n",
       "48830                          0                       0                    0   \n",
       "48837                          0                       0                    0   \n",
       "48839                          0                       0                    0   \n",
       "48841                          0                       0                    0   \n",
       "\n",
       "       native_country_Greece  native_country_Trinadad&Tobago  \\\n",
       "8                          0                               0   \n",
       "12                         0                               0   \n",
       "17                         0                               0   \n",
       "18                         0                               0   \n",
       "21                         0                               0   \n",
       "...                      ...                             ...   \n",
       "48827                      0                               0   \n",
       "48830                      0                               0   \n",
       "48837                      0                               0   \n",
       "48839                      0                               0   \n",
       "48841                      0                               0   \n",
       "\n",
       "       native_country_Outlying-US(Guam-USVI-etc)  native_country_France  \\\n",
       "8                                              0                      0   \n",
       "12                                             0                      0   \n",
       "17                                             0                      0   \n",
       "18                                             0                      0   \n",
       "21                                             0                      0   \n",
       "...                                          ...                    ...   \n",
       "48827                                          0                      0   \n",
       "48830                                          0                      0   \n",
       "48837                                          0                      0   \n",
       "48839                                          0                      0   \n",
       "48841                                          0                      0   \n",
       "\n",
       "       native_country_Holand-Netherlands  \n",
       "8                                      0  \n",
       "12                                     0  \n",
       "17                                     0  \n",
       "18                                     0  \n",
       "21                                     0  \n",
       "...                                  ...  \n",
       "48827                                  0  \n",
       "48830                                  0  \n",
       "48837                                  0  \n",
       "48839                                  0  \n",
       "48841                                  0  \n",
       "\n",
       "[14919 rows x 102 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a14c0c9-e145-456c-9d0c-51e0ad6cbc40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1390031/1002652701.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfx_1[cols] = minmax_scale(dfx_1[cols])\n",
      "/tmp/ipykernel_1390031/1002652701.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfx_0[cols] = minmax_scale(dfx_0[cols])\n"
     ]
    }
   ],
   "source": [
    "dfx_1[cols] = minmax_scale(dfx_1[cols])\n",
    "dfx_0[cols] = minmax_scale(dfx_0[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23905a44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_x1 = dfx_1.sample(1000)\n",
    "df_x0 = dfx_0.sample(1000)\n",
    "\n",
    "warm_start_y1 = torch.from_numpy(dfy.loc[df_x1.index].values).to(device)\n",
    "warm_start_y0 = torch.from_numpy(dfy.loc[df_x0.index].values).to(device)\n",
    "\n",
    "warm_start_x1 = torch.from_numpy(df_x1.values).float().to(device)\n",
    "warm_start_x0 = torch.from_numpy(df_x0.values).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "778e918e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de40baefbe3d40d1b23470096cb20796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d9b387ca7a04d87a31e2f0c5e519151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DirichletClassificationLikelihood(\n",
       "  (noise_covar): FixedGaussianNoise()\n",
       "  (second_noise_covar): HomoskedasticNoise(\n",
       "    (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0, likelihood0 = train(warm_start_x0, warm_start_y0)\n",
    "model1, likelihood1 = train(warm_start_x1, warm_start_y1)\n",
    "\n",
    "model0.to(device)\n",
    "likelihood0.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70dfc7c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model0.eval(), model1.eval(), likelihood0.eval(), likelihood1.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9091e699",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vae_models import VanillaVAE as vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a226a3c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vae0 = vae()\n",
    "vae0.load_state_dict(torch.load(\"checkpoints/adult_income/vae_xA=0/best.pt\"))\n",
    "vae0.eval()\n",
    "vae0.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0922ec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vae1 = vae()\n",
    "vae1.load_state_dict(torch.load(\"checkpoints/adult_income/vae_xA=1/best.pt\"))\n",
    "vae1.eval()\n",
    "vae1.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e759cd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from blackbox_models import BlackBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "933d864a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "blackbox = BlackBox('Logistic', 102, 1)\n",
    "blackbox.load_state_dict(torch.load(\"/mnt/infonas/data/eeshaan/fairness/EE492/checkpoints/adult_income/blackbox/Logistic/best.pt\"))\n",
    "blackbox.eval()\n",
    "blackbox.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea1f072",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6130aa2e06684b7886e53d9c4e94ec9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1100, 1]) torch.int64\n",
      "torch.Size([1100, 102]) torch.float32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd6e344708742c7bbcbac994300ac61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lambda_reg = 1.0\n",
    "candidates = []\n",
    "neg_queried = warm_start_x0.clone()\n",
    "neg_labels = warm_start_y0.clone().unsqueeze(1)\n",
    "\n",
    "for epoch_outer in tqdm(range(1, 4001)):\n",
    "    x0_random = torch.normal(0.,1.,size=(1,102), dtype=torch.float32, requires_grad=True)\n",
    "    optimizer0 = torch.optim.AdamW((x0_random,), lr=2)\n",
    "    best_loss = 10e5\n",
    "    count = 0\n",
    "    losses = []\n",
    "    for epoch in range(1,100):\n",
    "        optimizer0.zero_grad()\n",
    "        x0_samples = utils.postprocess(\n",
    "            vae0.sample(x0_random.to(device), 100, device, \n",
    "                        **{'tau': 1.0, 'tau_min': 0.1, 'anneal_rate': 3e-5, 'steps': 0, 'hard': False}).squeeze(1),\n",
    "            'adult_income'\n",
    "        )\n",
    "        obj0 = likelihood0(model0(x0_samples.to(device))).variance.sum(axis=0).mean() - lambda_reg * ((x0_random.to(device) - x0_samples)**2).mean()\n",
    "#         print(obj0.shape)\n",
    "        loss = -obj0\n",
    "        loss.backward()\n",
    "        optimizer0.step()\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            count = 0\n",
    "            losses.append(loss)\n",
    "        else:\n",
    "            count += 1\n",
    "        if count  == 5:\n",
    "            break\n",
    "    x0_query = dfx_0.iloc[np.argmin(np.linalg.norm(np.array(dfx_0) - x0_random.detach().clone().numpy()))]\n",
    "    candidates.append(torch.Tensor([x0_query]).float().to(device))\n",
    "    \n",
    "    if epoch_outer % 100 == 0:\n",
    "        new_vals = torch.concatenate(candidates)\n",
    "        new_queries,_, _ = vae0(new_vals.to(device), **{'tau': 1.0, 'tau_min': 0.1, 'anneal_rate': 3e-5, 'steps': 0, 'hard': False})\n",
    "        new_labels = blackbox(new_queries)\n",
    "        neg_queried = torch.concatenate([neg_queried, new_queries])\n",
    "        neg_labels = torch.concatenate([neg_labels, (0.5*(torch.sign(new_labels - 0.5) + 1.0)).long().detach().clone()])\n",
    "        print(neg_labels.shape, neg_labels.dtype)\n",
    "        print(neg_queried.shape, neg_queried.dtype)\n",
    "        model0, likelihood0 = train(neg_queried.detach().clone(),neg_labels.flatten())\n",
    "        model0.eval()\n",
    "        likelihood0.eval()\n",
    "        candidates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a6b87b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "candidates = []\n",
    "pos_queried = warm_start_x1.clone()\n",
    "pos_labels = warm_start_y1.clone().unsqueeze(1)\n",
    "print(pos_labels.shape, pos_labels.dtype)\n",
    "print(pos_queried.shape, pos_queried.dtype)\n",
    "\n",
    "for epoch_outer in tqdm(range(1, 4001)):\n",
    "    x1_random = torch.normal(0.,1.,size=(1,102), dtype=torch.float32, requires_grad=True)\n",
    "    optimizer1 = torch.optim.AdamW((x1_random,), lr=1)\n",
    "    best_loss = 10e5\n",
    "    count = 0\n",
    "    losses = []\n",
    "    for epoch in range(1,100):\n",
    "        optimizer1.zero_grad()\n",
    "        x1_samples = utils.postprocess(\n",
    "            vae1.sample(x1_random.to(device), 100, device, \n",
    "                        **{'tau': 1.0, 'tau_min': 0.1, 'anneal_rate': 3e-5, 'steps': 0, 'hard': False}).squeeze(1),\n",
    "            'adult_income'\n",
    "        )\n",
    "        obj1 = likelihood1(model1(x1_samples.to(device))).variance.sum(axis=0).mean() - lambda_reg * ((x1_random.to(device) - x1_samples)**2).mean()\n",
    "#         print(obj0.shape)\n",
    "        loss = -obj1\n",
    "        loss.backward()\n",
    "        optimizer1.step()\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            count = 0\n",
    "            losses.append(loss)\n",
    "        else:\n",
    "            count += 1\n",
    "        if count  == 5:\n",
    "            break\n",
    "    x1_query = dfx_1.iloc[np.argmin(np.linalg.norm(np.array(dfx_1) - x1_random.detach().clone().numpy()))]\n",
    "    candidates.append(torch.Tensor([x1_query]).float().to(device))\n",
    "    \n",
    "    if epoch_outer % 100 == 0:\n",
    "        new_vals = torch.concatenate(candidates)\n",
    "        new_queries,_ , _ = vae1(new_vals.to(device), **{'tau': 1.0, 'tau_min': 0.1, 'anneal_rate': 3e-5, 'steps': 0, 'hard': False})\n",
    "        new_labels = blackbox(new_queries)\n",
    "        pos_queried = torch.concatenate([pos_queried, new_queries])\n",
    "        pos_labels = torch.concatenate([pos_labels, (0.5*(torch.sign(new_labels - 0.5) + 1.0)).long().detach().clone()])\n",
    "        model1, likelihood1 = train(pos_queried.detach().clone(),pos_labels.flatten())\n",
    "        model1.eval()\n",
    "        likelihood1.eval()\n",
    "        candidates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee3f53a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba3888ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82ea831e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19911019753072282"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parity in data\n",
    "np.abs(dfy[dfx[dfx.gender == 0].index].mean() - dfy[dfx[dfx.gender == 1].index].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "684ded57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bb_input0 = torch.from_numpy(dfx_0.values).float().to(device)\n",
    "bb_input1 = torch.from_numpy(dfx_1.values).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a4f2648-312a-4892-b559-726fc4f983bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y0 = blackbox(bb_input0)\n",
    "y1 = blackbox(bb_input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53cac80a-56d0-45b1-b964-95ca2074d27d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y0_ = torch.round(y0)\n",
    "y1_ = torch.round(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b3f90e4-0472-46e6-909d-04d52f193dfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7659., device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y0_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30e43df0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1869, device='cuda:0', grad_fn=<AbsBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(y0_.mean() - y1_.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "890e743e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0982, device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(pos_labels.squeeze().float().mean() - neg_labels.squeeze().float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "63f393a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0520, device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_labels.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea69664a-6988-471e-a299-c9ed538aab04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1502, device='cuda:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_labels.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738ccfdc-775d-494a-a237-9272da4ebdc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
