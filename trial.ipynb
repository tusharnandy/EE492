{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "630bf96d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import math\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import os\n",
    "from math import floor\n",
    "from tqdm import tqdm\n",
    "from blackbox_preaudit import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92228ac9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_device = 0\n",
    "device = torch.device(f'cuda:{num_device}' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2cdebf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vae import VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b46d3fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vae1 = VAE(102, 64, 16)\n",
    "checkpoint = torch.load('checkpoints/vae1.pth')\n",
    "vae1.load_state_dict(checkpoint['model_state_dict'])\n",
    "vae1.to(device)\n",
    "vae1.eval();\n",
    "\n",
    "vae0 = VAE(102, 64, 16)\n",
    "checkpoint = torch.load('checkpoints/vae0.pth')\n",
    "vae0.load_state_dict(checkpoint['model_state_dict'])\n",
    "vae0.to(device)\n",
    "vae0.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69928115",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55459534",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d3260687",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dim = 102\n",
    "\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "def train(train_x, train_y):\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    model = ExactGPModel(train_x, train_y, likelihood)\n",
    "    model.to(device)\n",
    "    likelihood.to(device)\n",
    "    training_iterations = 60\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "    iterator = range(training_iterations)\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "    for i in range(training_iterations):\n",
    "        # Zero backprop gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Get output from model\n",
    "        output = model(train_x.to(device))\n",
    "        # Calc loss and backprop derivatives\n",
    "        loss = -mll(output, train_y.to(device))\n",
    "        loss.backward()\n",
    "        print(f'Epoch: {i+1}/{training_iterations}\\tLoss: {loss}')\n",
    "        optimizer.step()\n",
    "    return model, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73764f9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_and_discard(database, sample_size):\n",
    "    samples = database.sample(sample_size)\n",
    "    database.drop(index=samples.index, inplace=True)\n",
    "    database.reset_index(drop=True, inplace=True)\n",
    "    return samples, database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b67f5aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ignite_pd(dataframe, split=False):\n",
    "    if split:\n",
    "        x,y = dataframe.drop(columns=dataframe.columns[-1]).values, dataframe[dataframe.columns[-1]].values\n",
    "        return torch.Tensor(x.astype(np.float32)).to(device), torch.Tensor(y.astype(np.float32)).to(device)\n",
    "    else:\n",
    "        return torch.tensor(dataframe.values.astype(np.float32)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51dd0db0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=102, out_features=50, bias=True)\n",
       "  (act): ReLU()\n",
       "  (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blackbox = Net()\n",
    "blackbox.load_state_dict(torch.load('checkpoints/blackbox_preaudit.pth', map_location=device))\n",
    "blackbox.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e17ad514-d150-4ed0-8ba8-9ac7177cfe51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gpytorch.models import ExactGP\n",
    "from gpytorch.likelihoods import DirichletClassificationLikelihood\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c286a930",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_base = pd.read_csv(\"../Data/data1.csv\")\n",
    "df_base.drop(['Unnamed: 0'], axis=1, inplace = True)\n",
    "\n",
    "df_base_pos = df_base[df_base['gender_Female'] > 0]\n",
    "df_base_neg = df_base[df_base['gender_Female'] <= 0]\n",
    "\n",
    "df_base_neg = df_base_neg.reset_index(drop=True).copy().drop(columns='income')\n",
    "df_base_pos = df_base_pos.reset_index(drop=True).copy().drop(columns='income')\n",
    "\n",
    "# sample_pos, df_base_pos = sample_and_discard(df_base_pos, 1000)\n",
    "# pos_queried = ignite_pd(sample_pos)\n",
    "# pos_labels = blackbox(pos_queried)\n",
    "\n",
    "sample_neg, df_base_neg = sample_and_discard(df_base_neg, 29527)\n",
    "neg_queried = ignite_pd(sample_neg)\n",
    "neg_labels = blackbox(neg_queried)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "22a3e69e-6420-422f-b2f5-f45214aaa2a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29527, 102)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "36331ee6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/infonas/data/eeshaan/fairness/audit_env/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/mnt/infonas/data/eeshaan/fairness/audit_env/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/mnt/infonas/data/eeshaan/fairness/audit_env/lib/python3.7/site-packages/gpytorch/functions/_pivoted_cholesky.py:118: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2115.)\n",
      "  [L, torch.triangular_solve(Krows[..., m:, :].transpose(-1, -2), L, upper=False)[0].transpose(-1, -2)],\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 3.25 GiB (GPU 0; 23.65 GiB total capacity; 16.28 GiB already allocated; 1.18 GiB free; 16.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7930/520628438.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model_neg, likelihood_neg = train(\n\u001b[1;32m      2\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_queried\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_7930/818260225.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_x, train_y)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Calc loss and backprop derivatives\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {i+1}/{training_iterations}\\tLoss: {loss}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/infonas/data/eeshaan/fairness/audit_env/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[1;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         )\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/infonas/data/eeshaan/fairness/audit_env/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m def grad(\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.25 GiB (GPU 0; 23.65 GiB total capacity; 16.28 GiB already allocated; 1.18 GiB free; 16.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "model_neg, likelihood_neg = train(\n",
    "    torch.tensor(neg_queried),\n",
    "    torch.tensor(neg_labels).flatten()\n",
    ")\n",
    "\n",
    "model_neg.eval()\n",
    "likelihood_neg.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e690f3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 4000/4000 [34:14<00:00,  1.95it/s]\n"
     ]
    }
   ],
   "source": [
    "candidates = []\n",
    "for epoch_outer in tqdm(range(1, 4001)):\n",
    "    x0_random = torch.normal(0.,1.,size=(1,101), requires_grad=True)\n",
    "    optimizer0 = torch.optim.AdamW((x0_random,), lr=10)\n",
    "    best_loss = 10e5\n",
    "    count = 0\n",
    "    losses = []\n",
    "    for epoch in range(1,100):\n",
    "        optimizer0.zero_grad()\n",
    "        x0_samples, _, _ = vae1(torch.concatenate([x0_random, torch.Tensor([[0.0]])], axis=1).to(device))\n",
    "        var0 = likelihood_neg(model_neg(x0_samples.to(device))).variance\n",
    "        loss = -var0\n",
    "        loss.backward()\n",
    "        optimizer0.step()\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            count = 0\n",
    "            losses.append(loss)\n",
    "        else:\n",
    "            count += 1\n",
    "        if count  == 5:\n",
    "            break\n",
    "    candidates.append(torch.concatenate([x0_random.detach().clone(), torch.Tensor([[0.0]])], axis=1))\n",
    "    \n",
    "    if epoch_outer % 500 == 0:\n",
    "        new_vals = torch.concatenate(candidates)\n",
    "        new_queries, _, _ = vae1(new_vals.to(device))\n",
    "        new_labels = blackbox(new_queries)\n",
    "        neg_queried = torch.concatenate([neg_queried, new_queries])\n",
    "        neg_labels = torch.concatenate([neg_labels, new_labels])\n",
    "        model_neg, likelihood_neg = train(\n",
    "            neg_queried.detach().clone(),\n",
    "            neg_labels.detach().clone().flatten())\n",
    "        model_neg.eval()\n",
    "        likelihood_neg.eval()\n",
    "        candidates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4304abc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 102])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_queried.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "716d9b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_954517/4059754406.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(pos_queried),\n",
      "/tmp/ipykernel_954517/4059754406.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(pos_labels).flatten())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianLikelihood(\n",
       "  (noise_covar): HomoskedasticNoise(\n",
       "    (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### training the GP ####\n",
    "model_pos, likelihood_pos = train(\n",
    "    torch.tensor(pos_queried),\n",
    "    torch.tensor(pos_labels).flatten())\n",
    "model_pos.eval()\n",
    "likelihood_pos.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adf48c50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▉                                                                      | 499/4000 [04:20<30:21,  1.92it/s]/tmp/ipykernel_954517/712994024.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(pos_queried),\n",
      "/tmp/ipykernel_954517/712994024.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(pos_labels).flatten())\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 4000/4000 [38:08<00:00,  1.75it/s]\n"
     ]
    }
   ],
   "source": [
    "candidates = []\n",
    "for epoch_outer in tqdm(range(1, 4001)):\n",
    "    x1_random = torch.normal(0.,1.,size=(1,101), requires_grad=True)\n",
    "    optimizer1 = torch.optim.AdamW((x1_random,), lr=10)\n",
    "    best_loss = 10e5\n",
    "    count = 0\n",
    "    losses = []\n",
    "    for epoch in range(1,100):\n",
    "        optimizer1.zero_grad()\n",
    "        x1_samples, _, _ = vae1(torch.concatenate([x1_random, torch.Tensor([[1.0]])], axis=1).to(device))\n",
    "        var1 = likelihood_pos(model_pos(x1_samples.to(device))).variance\n",
    "        loss = -var1\n",
    "        loss.backward()\n",
    "        optimizer1.step()\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            count = 0\n",
    "            losses.append(loss)\n",
    "        else:\n",
    "            count += 1\n",
    "        if count  == 5:\n",
    "            break\n",
    "    candidates.append(torch.concatenate([x1_random.detach().clone(), torch.Tensor([[1.0]])], axis=1))\n",
    "    \n",
    "    if epoch_outer % 500 == 0:\n",
    "        new_vals = torch.concatenate(candidates)\n",
    "        new_queries, _, _ = vae1(new_vals.to(device))\n",
    "        new_labels = blackbox(new_queries)\n",
    "        pos_queried = torch.concatenate([pos_queried, new_queries])\n",
    "        pos_labels = torch.concatenate([pos_labels, new_labels])\n",
    "        model_pos, likelihood_pos = train(\n",
    "            torch.tensor(pos_queried),\n",
    "            torch.tensor(pos_labels).flatten())\n",
    "        model_pos.eval()\n",
    "        likelihood_pos.eval()\n",
    "        candidates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5a410e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_parity = torch.abs(pos_labels.mean() - neg_labels.mean()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d0c3c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pos = ignite_pd(df_base[df_base['gender_Female'] == 1].drop(columns='income'))\n",
    "X_neg = ignite_pd(df_base[df_base['gender_Female'] == 0].drop(columns='income'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48e16821",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_parity = torch.abs(blackbox(X_pos).mean() - blackbox(X_neg).mean()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30e8983f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0012248754501342773 0.007420867681503296\n"
     ]
    }
   ],
   "source": [
    "print(estimated_parity, actual_parity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4502a63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error =  83.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"error = \", np.round(np.abs(estimated_parity-actual_parity)*100/actual_parity), \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "1623887a4657fbc55005e133332f3be3f5efee82a88b4990fa1707cdaeddf772"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
