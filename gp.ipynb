{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import math\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import os\n",
    "from math import floor\n",
    "import black_box\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dim = 102\n",
    "\n",
    "class FCN(torch.nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super(FCN, self).__init__()\n",
    "        self.add_module('linear1', torch.nn.Linear(data_dim, 50))\n",
    "        self.add_module('relu1', torch.nn.ReLU())\n",
    "        self.add_module('linear2', torch.nn.Linear(50, 2))\n",
    "\n",
    "feature_extractor = FCN()\n",
    "\n",
    "class GPRegressionModel(gpytorch.models.ExactGP):\n",
    "        def __init__(self, train_x, train_y, likelihood):\n",
    "            super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)\n",
    "            self.mean_module = gpytorch.means.ConstantMean()\n",
    "            self.covar_module = gpytorch.kernels.GridInterpolationKernel(\n",
    "                gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=2)),\n",
    "                num_dims=2, grid_size=100\n",
    "            )\n",
    "            self.feature_extractor = feature_extractor\n",
    "\n",
    "            # This module will scale the NN features so that they're nice values\n",
    "            self.scale_to_bounds = gpytorch.utils.grid.ScaleToBounds(-1., 1.)\n",
    "\n",
    "        def forward(self, x):\n",
    "            # We're first putting our data through a deep net (feature extractor)\n",
    "            projected_x = self.feature_extractor(x)\n",
    "            projected_x = self.scale_to_bounds(projected_x)  # Make the NN values \"nice\"\n",
    "\n",
    "            mean_x = self.mean_module(projected_x)\n",
    "            covar_x = self.covar_module(projected_x)\n",
    "            return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "def train(train_x, train_y, num_device=0):\n",
    "    device = torch.device(f'cuda:{num_device}' if torch.cuda.is_available() else 'cpu')\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    model = GPRegressionModel(train_x, train_y, likelihood)\n",
    "\n",
    "    model.to(device)\n",
    "    likelihood.to(device)\n",
    "\n",
    "    training_iterations = 60\n",
    "\n",
    "    optimizer = torch.optim.Adam([\n",
    "    {'params': model.feature_extractor.parameters()},\n",
    "    {'params': model.covar_module.parameters()},\n",
    "    {'params': model.mean_module.parameters()},\n",
    "    {'params': model.likelihood.parameters()},], lr=0.01)\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    demo_parity = 0\n",
    "    iterator = range(training_iterations)\n",
    "    \n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "    \n",
    "    best_loss = 10e5\n",
    "    penalty_count = 0\n",
    "    for i in tqdm.tqdm(range(training_iterations)):\n",
    "#         print(i)\n",
    "        # Zero backprop gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Get output from model\n",
    "        output = model(train_x.to(device))\n",
    "\n",
    "        # Calc loss and backprop derivatives\n",
    "        loss = -mll(output, train_y.to(device))\n",
    "        \n",
    "        if loss >= best_loss:\n",
    "            penalty_count += 1\n",
    "        else:\n",
    "            penalty_count = 0\n",
    "            best_loss = loss\n",
    "        \n",
    "        if penalty_count == 5:\n",
    "            break\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        #     model.eval()\n",
    "        #     likelihood.eval()\n",
    "\n",
    "    return model, likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
